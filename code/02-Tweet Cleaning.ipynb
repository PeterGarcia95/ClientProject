{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning Tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "import regex as re\n",
    "import nltk\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.read_csv('../datasets/raw_data/raw_tweets.csv').drop(columns='Unnamed: 0')\n",
    "df1['label']='outage'\n",
    "df2=pd.read_csv('../datasets/raw_data/irrelevent_tweets.csv').drop(columns='Unnamed: 0')\n",
    "df2['label']='irrelevant'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.concat([df1,df2],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['dates']=pd.to_datetime(df.date).dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['dates']=pd.to_datetime(df.dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "username            object\n",
       "text                object\n",
       "date                object\n",
       "label               object\n",
       "dates       datetime64[ns]\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(columns=['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>dates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>JulieWilcoxWX</td>\n",
       "      <td>An emergency manager once explained it this wa...</td>\n",
       "      <td>outage</td>\n",
       "      <td>2019-08-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>hays_wood</td>\n",
       "      <td>@Xfinity get your shit together! First college...</td>\n",
       "      <td>outage</td>\n",
       "      <td>2019-08-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>EdValleeWx</td>\n",
       "      <td>Have had many ask me what to do for prep. Here...</td>\n",
       "      <td>outage</td>\n",
       "      <td>2019-08-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>teamworkf1</td>\n",
       "      <td>@RogersHelps - GM, is any outage in the Duffer...</td>\n",
       "      <td>outage</td>\n",
       "      <td>2019-08-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>shellz_woo</td>\n",
       "      <td>Solar lights that people use outside to light ...</td>\n",
       "      <td>outage</td>\n",
       "      <td>2019-08-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        username                                               text   label  \\\n",
       "0  JulieWilcoxWX  An emergency manager once explained it this wa...  outage   \n",
       "1      hays_wood  @Xfinity get your shit together! First college...  outage   \n",
       "2     EdValleeWx  Have had many ask me what to do for prep. Here...  outage   \n",
       "3     teamworkf1  @RogersHelps - GM, is any outage in the Duffer...  outage   \n",
       "4     shellz_woo  Solar lights that people use outside to light ...  outage   \n",
       "\n",
       "       dates  \n",
       "0 2019-08-31  \n",
       "1 2019-08-31  \n",
       "2 2019-08-31  \n",
       "3 2019-08-31  \n",
       "4 2019-08-31  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(how='any',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Stop Words and HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweet_cleaning(raw_tweet):\n",
    "    \n",
    "    # 1. Remove HTML\n",
    "    tweet_text = BeautifulSoup(raw_tweet).get_text()\n",
    "    \n",
    "    # 2. Remove punctuation, keep numbers with 1-4 digits\n",
    "    letters_numbers_only = re.sub(\"[^a-zA-Z]\", \" \", tweet_text)\n",
    "    latin = re.sub(\"r'[\\p{Latin}]'\", \" \", letters_numbers_only)\n",
    "    \n",
    "    # 3. Convert to lower case, split into individual words.\n",
    "    words = latin.lower().split()\n",
    "    \n",
    "    # 4. Search\n",
    "    stops = set(stopwords)\n",
    "    \n",
    "    # 5. Stop Words\n",
    "    meaningful_words = [w for w in words if not w in stops]\n",
    "    \n",
    "    # 6. Join \n",
    "    return(\" \".join(meaningful_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 61263 tweets.\n"
     ]
    }
   ],
   "source": [
    "# Tweet Count\n",
    "total_tweets = df.shape[0]\n",
    "print(f'There are {total_tweets} tweets.')\n",
    "\n",
    "# List holders\n",
    "clean_train_tweets = []\n",
    "clean_test_tweets = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning and parsing tweets...\n",
      "Tweet 1000 of 61263.\n",
      "Tweet 2000 of 61263.\n",
      "Tweet 3000 of 61263.\n",
      "Tweet 4000 of 61263.\n",
      "Tweet 5000 of 61263.\n",
      "Tweet 6000 of 61263.\n",
      "Tweet 7000 of 61263.\n",
      "Tweet 8000 of 61263.\n",
      "Tweet 9000 of 61263.\n",
      "Tweet 10000 of 61263.\n",
      "Tweet 11000 of 61263.\n",
      "Tweet 12000 of 61263.\n",
      "Tweet 13000 of 61263.\n",
      "Tweet 14000 of 61263.\n",
      "Tweet 15000 of 61263.\n",
      "Tweet 16000 of 61263.\n",
      "Tweet 17000 of 61263.\n",
      "Tweet 18000 of 61263.\n",
      "Tweet 19000 of 61263.\n",
      "Tweet 20000 of 61263.\n",
      "Tweet 21000 of 61263.\n",
      "Tweet 22000 of 61263.\n",
      "Tweet 23000 of 61263.\n",
      "Tweet 24000 of 61263.\n",
      "Tweet 25000 of 61263.\n",
      "Tweet 26000 of 61263.\n",
      "Tweet 27000 of 61263.\n",
      "Tweet 28000 of 61263.\n",
      "Tweet 29000 of 61263.\n",
      "Tweet 30000 of 61263.\n",
      "Tweet 31000 of 61263.\n",
      "Tweet 32000 of 61263.\n",
      "Tweet 33000 of 61263.\n",
      "Tweet 34000 of 61263.\n",
      "Tweet 35000 of 61263.\n",
      "Tweet 36000 of 61263.\n",
      "Tweet 37000 of 61263.\n",
      "Tweet 38000 of 61263.\n",
      "Tweet 39000 of 61263.\n",
      "Tweet 40000 of 61263.\n",
      "Tweet 41000 of 61263.\n",
      "Tweet 42000 of 61263.\n",
      "Tweet 43000 of 61263.\n",
      "Tweet 44000 of 61263.\n",
      "Tweet 45000 of 61263.\n",
      "Tweet 46000 of 61263.\n",
      "Tweet 47000 of 61263.\n",
      "Tweet 48000 of 61263.\n",
      "Tweet 49000 of 61263.\n",
      "Tweet 50000 of 61263.\n",
      "Tweet 51000 of 61263.\n",
      "Tweet 52000 of 61263.\n",
      "Tweet 53000 of 61263.\n",
      "Tweet 54000 of 61263.\n",
      "Tweet 55000 of 61263.\n",
      "Tweet 56000 of 61263.\n",
      "Tweet 57000 of 61263.\n",
      "Tweet 58000 of 61263.\n",
      "Tweet 59000 of 61263.\n",
      "Tweet 60000 of 61263.\n",
      "Tweet 61000 of 61263.\n",
      "Cleaning and parsing the testing set ...\n"
     ]
    }
   ],
   "source": [
    "#Running the functions\n",
    "print(\"Cleaning and parsing tweets...\")\n",
    "\n",
    "j = 0\n",
    "for train_tweet in df['text']:\n",
    "    # Join clean tweets\n",
    "    clean_train_tweets.append(tweet_cleaning(train_tweet))\n",
    "    \n",
    "    # Message to keep track\n",
    "    if (j + 1) % 1000 == 0:\n",
    "        print(f'Tweet {j + 1} of {total_tweets}.')\n",
    "    \n",
    "    j += 1\n",
    "\n",
    "print(\"Cleaning and parsing the testing set ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean_text']=clean_train_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>dates</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50013</td>\n",
       "      <td>kaedenoha_89</td>\n",
       "      <td>待ってどれwwww</td>\n",
       "      <td>irrelevant</td>\n",
       "      <td>2019-08-31</td>\n",
       "      <td>wwww</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50014</td>\n",
       "      <td>hhacffcvhim</td>\n",
       "      <td>للآن يتصالحون واالشعوب مركونين بالفراغ المميت ...</td>\n",
       "      <td>irrelevant</td>\n",
       "      <td>2019-08-31</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50015</td>\n",
       "      <td>hito_yr</td>\n",
       "      <td>Jimin in Paris, official video \\n#JIMINpic.twi...</td>\n",
       "      <td>irrelevant</td>\n",
       "      <td>2019-08-31</td>\n",
       "      <td>jimin paris official video jiminpic twitter co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50016</td>\n",
       "      <td>joelbirch</td>\n",
       "      <td>Your name is MŸKKECÅRLT now. You will require ...</td>\n",
       "      <td>irrelevant</td>\n",
       "      <td>2019-08-31</td>\n",
       "      <td>name kkec rlt require assembly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50017</td>\n",
       "      <td>takapzdra91</td>\n",
       "      <td>まひちゃん熱中症ならなくてよかった(๑•ᴗ•๑)</td>\n",
       "      <td>irrelevant</td>\n",
       "      <td>2019-08-31</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           username                                               text  \\\n",
       "50013  kaedenoha_89                                          待ってどれwwww   \n",
       "50014   hhacffcvhim  للآن يتصالحون واالشعوب مركونين بالفراغ المميت ...   \n",
       "50015       hito_yr  Jimin in Paris, official video \\n#JIMINpic.twi...   \n",
       "50016     joelbirch  Your name is MŸKKECÅRLT now. You will require ...   \n",
       "50017   takapzdra91                           まひちゃん熱中症ならなくてよかった(๑•ᴗ•๑)   \n",
       "\n",
       "            label      dates  \\\n",
       "50013  irrelevant 2019-08-31   \n",
       "50014  irrelevant 2019-08-31   \n",
       "50015  irrelevant 2019-08-31   \n",
       "50016  irrelevant 2019-08-31   \n",
       "50017  irrelevant 2019-08-31   \n",
       "\n",
       "                                              clean_text  \n",
       "50013                                               wwww  \n",
       "50014                                                     \n",
       "50015  jimin paris official video jiminpic twitter co...  \n",
       "50016                     name kkec rlt require assembly  \n",
       "50017                                                     "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(how='any',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter by Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets=pd.read_csv('../datasets/DoE/Outages_since_2014.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date Event Began</th>\n",
       "      <th>Time Event Began</th>\n",
       "      <th>Date of Restoration</th>\n",
       "      <th>Time of Restoration</th>\n",
       "      <th>Area Affected</th>\n",
       "      <th>NERC Region</th>\n",
       "      <th>Event Type</th>\n",
       "      <th>Number of Customers Affected</th>\n",
       "      <th>Alert Criteria</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>10/22/2014</td>\n",
       "      <td>10:46 PM</td>\n",
       "      <td>10/22/2014</td>\n",
       "      <td>10:47 PM</td>\n",
       "      <td>New Hampshire, Maine, Massachusetts, Rhode Isl...</td>\n",
       "      <td>NPCC</td>\n",
       "      <td>Severe Weather</td>\n",
       "      <td>66,650</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>6/23/2015</td>\n",
       "      <td>6:30 PM</td>\n",
       "      <td>6/24/2015</td>\n",
       "      <td>5:00 AM</td>\n",
       "      <td>Connecticut, Maine, Massachusetts, New Hampshi...</td>\n",
       "      <td>NPCC</td>\n",
       "      <td>Severe Weather</td>\n",
       "      <td>62,442</td>\n",
       "      <td>Loss of electric service to more than 50,000 c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>8/4/2015</td>\n",
       "      <td>7:17 AM</td>\n",
       "      <td>8/5/2015</td>\n",
       "      <td>12:52 PM</td>\n",
       "      <td>Massachusetts: Rhode Island:</td>\n",
       "      <td>NPCC</td>\n",
       "      <td>Severe Weather</td>\n",
       "      <td>132,000</td>\n",
       "      <td>Loss of electric service to more than 50,000 c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>7/22/2016</td>\n",
       "      <td>11:50 PM</td>\n",
       "      <td>7/23/2016</td>\n",
       "      <td>9:10 AM</td>\n",
       "      <td>Massachusetts: Connecticut: Rhode Island: New ...</td>\n",
       "      <td>NPCC</td>\n",
       "      <td>Severe Weather</td>\n",
       "      <td>57058</td>\n",
       "      <td>Loss of electric service to more than 50,000 c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>7/23/2016</td>\n",
       "      <td>7:30 PM</td>\n",
       "      <td>7/24/2016</td>\n",
       "      <td>7:30 AM</td>\n",
       "      <td>Connecticut: Massachusetts: New Hampshire: Ver...</td>\n",
       "      <td>NPCC</td>\n",
       "      <td>Severe Weather</td>\n",
       "      <td>101073</td>\n",
       "      <td>Loss of electric service to more than 50,000 c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Date Event Began Time Event Began Date of Restoration Time of Restoration  \\\n",
       "0       10/22/2014         10:46 PM          10/22/2014            10:47 PM   \n",
       "1        6/23/2015          6:30 PM           6/24/2015             5:00 AM   \n",
       "2         8/4/2015          7:17 AM            8/5/2015            12:52 PM   \n",
       "3        7/22/2016         11:50 PM           7/23/2016             9:10 AM   \n",
       "4        7/23/2016          7:30 PM           7/24/2016             7:30 AM   \n",
       "\n",
       "                                       Area Affected NERC Region  \\\n",
       "0  New Hampshire, Maine, Massachusetts, Rhode Isl...        NPCC   \n",
       "1  Connecticut, Maine, Massachusetts, New Hampshi...        NPCC   \n",
       "2                       Massachusetts: Rhode Island:        NPCC   \n",
       "3  Massachusetts: Connecticut: Rhode Island: New ...        NPCC   \n",
       "4  Connecticut: Massachusetts: New Hampshire: Ver...        NPCC   \n",
       "\n",
       "       Event Type Number of Customers Affected  \\\n",
       "0  Severe Weather                       66,650   \n",
       "1  Severe Weather                       62,442   \n",
       "2  Severe Weather                      132,000   \n",
       "3  Severe Weather                        57058   \n",
       "4  Severe Weather                       101073   \n",
       "\n",
       "                                      Alert Criteria  \n",
       "0                                                NaN  \n",
       "1  Loss of electric service to more than 50,000 c...  \n",
       "2  Loss of electric service to more than 50,000 c...  \n",
       "3  Loss of electric service to more than 50,000 c...  \n",
       "4  Loss of electric service to more than 50,000 c...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Each value in the nested list is a date that the blackout occured\n",
    "blackouts = [pd.date_range(start = targets.loc[i ,'Date Event Began'], end = targets.loc[i, 'Date of Restoration'])for i in targets.index]\n",
    "\n",
    "# Flatten the 2d list to 1d\n",
    "# https://www.geeksforgeeks.org/python-ways-to-flatten-a-2d-list/\n",
    "blackouts = [j for sub in blackouts for j in sub]\n",
    "\n",
    "# Number of tweets that occured during an actual blackout\n",
    "df['dates'].isin(blackouts).sum()\n",
    "\n",
    "df['target'] = df['dates'].isin(blackouts)\n",
    "df['target'] *= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>dates</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>JulieWilcoxWX</td>\n",
       "      <td>An emergency manager once explained it this wa...</td>\n",
       "      <td>outage</td>\n",
       "      <td>2019-08-31</td>\n",
       "      <td>emergency manager explained way interview imag...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>hays_wood</td>\n",
       "      <td>@Xfinity get your shit together! First college...</td>\n",
       "      <td>outage</td>\n",
       "      <td>2019-08-31</td>\n",
       "      <td>xfinity get shit together first college footba...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>EdValleeWx</td>\n",
       "      <td>Have had many ask me what to do for prep. Here...</td>\n",
       "      <td>outage</td>\n",
       "      <td>2019-08-31</td>\n",
       "      <td>many ask prep done orlando fl reference water ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>teamworkf1</td>\n",
       "      <td>@RogersHelps - GM, is any outage in the Duffer...</td>\n",
       "      <td>outage</td>\n",
       "      <td>2019-08-31</td>\n",
       "      <td>rogershelps gm outage dufferin queen area sinc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>shellz_woo</td>\n",
       "      <td>Solar lights that people use outside to light ...</td>\n",
       "      <td>outage</td>\n",
       "      <td>2019-08-31</td>\n",
       "      <td>solar lights people use outside light pathways...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        username                                               text   label  \\\n",
       "0  JulieWilcoxWX  An emergency manager once explained it this wa...  outage   \n",
       "1      hays_wood  @Xfinity get your shit together! First college...  outage   \n",
       "2     EdValleeWx  Have had many ask me what to do for prep. Here...  outage   \n",
       "3     teamworkf1  @RogersHelps - GM, is any outage in the Duffer...  outage   \n",
       "4     shellz_woo  Solar lights that people use outside to light ...  outage   \n",
       "\n",
       "       dates                                         clean_text  target  \n",
       "0 2019-08-31  emergency manager explained way interview imag...       0  \n",
       "1 2019-08-31  xfinity get shit together first college footba...       0  \n",
       "2 2019-08-31  many ask prep done orlando fl reference water ...       0  \n",
       "3 2019-08-31  rogershelps gm outage dufferin queen area sinc...       0  \n",
       "4 2019-08-31  solar lights people use outside light pathways...       0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "491"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.target.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class Imbalance Fix - Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1491, 6)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Undersample majority class\n",
    "fakenews = df[df['target'] == 0]\n",
    "fakenews_subset = fakenews.sample(n = 1000, random_state=42)\n",
    "fakenews_subset\n",
    "\n",
    "final_df = pd.concat([df[df['target'] == 1], fakenews_subset], axis = 0)\n",
    "final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1491"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulating Random Boston Coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#latitude\n",
    "coor_lat=range(42229077, 42397652)\n",
    "latitudes=np.random.choice(coor_lat, size=final_df.shape[0])\n",
    "latitudes=latitudes/1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#longitude\n",
    "coor_long=range(-71203220, -70987133)\n",
    "longitude=np.random.choice(coor_long, size=final_df.shape[0])\n",
    "longitude=longitude/1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#zipcode\n",
    "coor_zip=['02108', '02109', '02110', '02111', '02113', '02114', '02115', '02116', '02118', '02119', '02120', '02121', '02122', '02124', '02125', '02126', '02127', '02128', '02129', '02130', '02131', '02132', '02134', '02135', '02136', '02151', '02152', '02163', '02199', '02203', '02210', '02215', '02467']\n",
    "zipcodes=np.random.choice(coor_zip, size=final_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['lat']=latitudes\n",
    "final_df['long']=longitude\n",
    "final_df['zip']=zipcodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>dates</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>target</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>zip</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>326</td>\n",
       "      <td>Amithridya1001</td>\n",
       "      <td>No update or action on supply issue at near 2 ...</td>\n",
       "      <td>outage</td>\n",
       "      <td>2019-07-23</td>\n",
       "      <td>update action supply issue near still even cus...</td>\n",
       "      <td>1</td>\n",
       "      <td>42.351035</td>\n",
       "      <td>-71.157572</td>\n",
       "      <td>02132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>327</td>\n",
       "      <td>ellensweeps</td>\n",
       "      <td>I live in what is considered the largest conce...</td>\n",
       "      <td>outage</td>\n",
       "      <td>2019-07-23</td>\n",
       "      <td>live considered largest concentrated outage ma...</td>\n",
       "      <td>1</td>\n",
       "      <td>42.375944</td>\n",
       "      <td>-71.077229</td>\n",
       "      <td>02121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>328</td>\n",
       "      <td>CoxHelp</td>\n",
       "      <td>No, there is not an outage and your modem is r...</td>\n",
       "      <td>outage</td>\n",
       "      <td>2019-07-23</td>\n",
       "      <td>outage modem receiving signal us reset modem f...</td>\n",
       "      <td>1</td>\n",
       "      <td>42.361009</td>\n",
       "      <td>-71.062632</td>\n",
       "      <td>02135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>329</td>\n",
       "      <td>Steven_McKie</td>\n",
       "      <td>No big deal @Xfinity I didn’t have to work tod...</td>\n",
       "      <td>outage</td>\n",
       "      <td>2019-07-23</td>\n",
       "      <td>big deal xfinity work today anything outage ni...</td>\n",
       "      <td>1</td>\n",
       "      <td>42.332771</td>\n",
       "      <td>-71.088215</td>\n",
       "      <td>02119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>Larapic</td>\n",
       "      <td>So we filled the Adpt with post-its today and ...</td>\n",
       "      <td>outage</td>\n",
       "      <td>2019-07-23</td>\n",
       "      <td>filled adpt post today second outage ended dis...</td>\n",
       "      <td>1</td>\n",
       "      <td>42.348956</td>\n",
       "      <td>-71.200824</td>\n",
       "      <td>02215</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           username                                               text  \\\n",
       "326  Amithridya1001  No update or action on supply issue at near 2 ...   \n",
       "327     ellensweeps  I live in what is considered the largest conce...   \n",
       "328         CoxHelp  No, there is not an outage and your modem is r...   \n",
       "329    Steven_McKie  No big deal @Xfinity I didn’t have to work tod...   \n",
       "330         Larapic  So we filled the Adpt with post-its today and ...   \n",
       "\n",
       "      label      dates                                         clean_text  \\\n",
       "326  outage 2019-07-23  update action supply issue near still even cus...   \n",
       "327  outage 2019-07-23  live considered largest concentrated outage ma...   \n",
       "328  outage 2019-07-23  outage modem receiving signal us reset modem f...   \n",
       "329  outage 2019-07-23  big deal xfinity work today anything outage ni...   \n",
       "330  outage 2019-07-23  filled adpt post today second outage ended dis...   \n",
       "\n",
       "     target        lat       long    zip  \n",
       "326       1  42.351035 -71.157572  02132  \n",
       "327       1  42.375944 -71.077229  02121  \n",
       "328       1  42.361009 -71.062632  02135  \n",
       "329       1  42.332771 -71.088215  02119  \n",
       "330       1  42.348956 -71.200824  02215  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv('../datasets/clean-tweets/clean_tweets.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
